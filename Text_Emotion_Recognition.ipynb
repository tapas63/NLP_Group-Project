{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Emotion_Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQSjkukWWeDt"
      },
      "source": [
        "**Imported necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6bnubCoWXnF"
      },
      "source": [
        "import re \n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2fq3ep-Xyiw"
      },
      "source": [
        "**Read the data from the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DP_u-EgjZixJ",
        "outputId": "85fad670-e023-4ed5-c9c0-81d155f0f454"
      },
      "source": [
        "def read_data(file):\n",
        "    data = []\n",
        "    with open(file, 'r')as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            label = ' '.join(line[1:line.find(\"]\")].strip().split())\n",
        "            text = line[line.find(\"]\")+1:].strip()\n",
        "            data.append([label, text])\n",
        "    return data\n",
        "\n",
        "file = '/content/sample_data/Dataset.txt'\n",
        "data = read_data(file)\n",
        "print(\"Number of instances: {}\".format(len(data)))\n",
        "print(data[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of instances: 7480\n",
            "['1. 0. 0. 0. 0. 0. 0.', 'During the period of falling in love, each time that we met and especially when we had not met for a long time.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1t-uNsbZn_-"
      },
      "source": [
        "**Perform tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGxd9jZdEY0K"
      },
      "source": [
        "def ngram(token, n): \n",
        "    output = []\n",
        "    for i in range(n-1, len(token)): \n",
        "        ngram = ' '.join(token[i-n+1:i+1])\n",
        "        output.append(ngram) \n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyLCkMdAZ15a"
      },
      "source": [
        "**Create feature using ngram**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJVFnWscZ2SX"
      },
      "source": [
        "def create_feature(text, nrange=(1, 1)):\n",
        "    text_features = [] \n",
        "    text = text.lower() \n",
        "    text_alphanum = re.sub('[^a-z0-9#]', ' ', text)\n",
        "    for n in range(nrange[0], nrange[1]+1): \n",
        "        text_features += ngram(text_alphanum.split(), n)    \n",
        "    text_punc = re.sub('[a-z0-9]', ' ', text)\n",
        "    text_features += ngram(text_punc.split(), 1)\n",
        "    return Counter(text_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6v_bE0mZxyJ"
      },
      "source": [
        "**Labels are being stored and will be based on emotions such as Joy, Fear, Anger, Sadness, Disgust, Shame and Guilt**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gFrt-RNEY2w"
      },
      "source": [
        "def convert_label(item, name): \n",
        "    items = list(map(float, item.split()))\n",
        "    label = \"\"\n",
        "    for idx in range(len(items)): \n",
        "        if items[idx] == 1: \n",
        "            label += name[idx] + \" \"\n",
        "                 \n",
        "    return label.strip()\n",
        "\n",
        "emotions = [\"joy\", 'fear', \"anger\", \"sadness\", \"disgust\", \"shame\", \"guilt\"]\n",
        "\n",
        "X_all = []\n",
        "y_all = []\n",
        "for label, text in data:\n",
        "    y_all.append(convert_label(label, emotions))\n",
        "    X_all.append(create_feature(text, nrange=(1, 4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYDx1DFCbRS7"
      },
      "source": [
        "**Splitting the data into training and testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-BW0xPkEY5a"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size = 0.2, random_state = 123)\n",
        "\n",
        "def train_test(clf, X_train, X_test, y_train, y_test):\n",
        "    clf.fit(X_train, y_train)\n",
        "    train_acc = accuracy_score(y_train, clf.predict(X_train))\n",
        "    test_acc = accuracy_score(y_test, clf.predict(X_test))\n",
        "    return train_acc, test_acc\n",
        "\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "vectorizer = DictVectorizer(sparse = True)\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDjIJpindn79"
      },
      "source": [
        "**Derive the accuracy using four different classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMdcn_MxEicc",
        "outputId": "46b06d0d-026b-4582-ee75-d2dc7874bf49"
      },
      "source": [
        "svc = SVC()\n",
        "lsvc = LinearSVC(random_state=123)\n",
        "rforest = RandomForestClassifier(random_state=123)\n",
        "dtree = DecisionTreeClassifier()\n",
        "\n",
        "clifs = [svc, lsvc, rforest, dtree]\n",
        "\n",
        "# train and test them \n",
        "print(\"| {:25} | {} | {} |\".format(\"Classifier\", \"Training Accuracy\", \"Test Accuracy\"))\n",
        "print(\"| {} | {} | {} |\".format(\"-\"*25, \"-\"*17, \"-\"*13))\n",
        "for clf in clifs: \n",
        "    clf_name = clf.__class__.__name__\n",
        "    train_acc, test_acc = train_test(clf, X_train, X_test, y_train, y_test)\n",
        "    print(\"| {:25} | {:17.7f} | {:13.7f} |\".format(clf_name, train_acc, test_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Classifier                | Training Accuracy | Test Accuracy |\n",
            "| ------------------------- | ----------------- | ------------- |\n",
            "| SVC                       |         0.9067513 |     0.4512032 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| LinearSVC                 |         0.9988302 |     0.5768717 |\n",
            "| RandomForestClassifier    |         0.9988302 |     0.5541444 |\n",
            "| DecisionTreeClassifier    |         0.9988302 |     0.4592246 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugLqMZUBf4KA"
      },
      "source": [
        "**Assigning an emoji to each label that is emotions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uocXQkelElIU",
        "outputId": "b189b6b7-bfe4-4cdf-c397-ebed55e734f0"
      },
      "source": [
        "l = [\"joy\", 'fear', \"anger\", \"sadness\", \"disgust\", \"shame\", \"guilt\"]\n",
        "l.sort()\n",
        "label_freq = {}\n",
        "for label, _ in data: \n",
        "    label_freq[label] = label_freq.get(label, 0) + 1\n",
        "\n",
        "# print the labels and their counts in sorted order \n",
        "for l in sorted(label_freq, key=label_freq.get, reverse=True):\n",
        "    print(\"{:10}({})  {}\".format(convert_label(l, emotions), l, label_freq[l]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "joy       (1. 0. 0. 0. 0. 0. 0.)  1084\n",
            "anger     (0. 0. 1. 0. 0. 0. 0.)  1080\n",
            "sadness   (0. 0. 0. 1. 0. 0. 0.)  1079\n",
            "fear      (0. 1. 0. 0. 0. 0. 0.)  1078\n",
            "disgust   (0. 0. 0. 0. 1. 0. 0.)  1057\n",
            "guilt     (0. 0. 0. 0. 0. 0. 1.)  1057\n",
            "shame     (0. 0. 0. 0. 0. 1. 0.)  1045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vg69l6_AhXAC"
      },
      "source": [
        "**Predict the emotion using trained model**\n",
        "**we have trained the model with four algorithm and we found all the models are overfitting with training data and high variance with testing data. As we found relativly high accuracy with Lsvc in testing data so we selected the Linearsvc for our final implementation.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKttKMF_ElPc",
        "outputId": "03caa42c-b759-4c47-9cf9-0e1ebc4b63c5"
      },
      "source": [
        "emoji_dict = {\"joy\":\"😂\", \"fear\":\"😱\", \"anger\":\"😠\", \"sadness\":\"😢\", \"disgust\":\"😒\", \"shame\":\"😳\", \"guilt\":\"😳\"}\n",
        "t1 = \"This looks so impressive\"\n",
        "t2 = \"I have a fear of dogs\"\n",
        "t3 = \"My dog died yesterday\"\n",
        "t4 = \"I don't love you anymore..!\"\n",
        "\n",
        "texts = [t1, t2, t3, t4]\n",
        "for text in texts: \n",
        "    features = create_feature(text, nrange=(1, 4))\n",
        "    features = vectorizer.transform(features)\n",
        "    prediction = lsvc.predict(features)[0]\n",
        "    print( text,emoji_dict[prediction])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This looks so impressive 😒\n",
            "I have a fear of dogs 😱\n",
            "My dog died yesterday 😢\n",
            "I don't love you anymore..! 😂\n"
          ]
        }
      ]
    }
  ]
}